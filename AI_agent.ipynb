{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aee18fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "63640968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict,Literal\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import json\n",
    "from langgraph.graph import StateGraph,END,START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d96abe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCalling(TypedDict):\n",
    "    \n",
    "    query : str\n",
    "    ans : str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7216d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: int,b: int) -> int:\n",
    "    \"\"\"For adding two numbers or when the + sign is between two numbers\"\"\"\n",
    "    \n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e33897a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_or_respond(state: ToolCalling):\n",
    "    llm_with_tools = llm.bind_tools([add])\n",
    "    response = llm_with_tools.invoke(state['query'])\n",
    "    \n",
    "    return {'ans' : response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "03bad694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools([add])\n",
    "response = llm_with_tools.invoke(\"Capital of china\")\n",
    "\n",
    "if response.tool_calls:\n",
    "    print(\"here\")\n",
    "else:\n",
    "    print('there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b2c10c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_node(state: ToolCalling) -> Literal['Tool_Call','Selfknowledge']:\n",
    "    response = state['ans']\n",
    "    if response.tool_calls:\n",
    "        return 'Tool_Call'\n",
    "    else:\n",
    "        return 'Selfknowledge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5d35a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Selfknowledge(state: ToolCalling):\n",
    "    query = state['query']\n",
    "    prompt = f'Give the ans to the query: {query}'\n",
    "    ans = llm.invoke(prompt)\n",
    "    return {'ans':ans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "918be3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tool_Call(state: ToolCalling):\n",
    "    response = state['ans']\n",
    "    tool_map = {'add':add,'subtract':subtract}\n",
    "    results = []\n",
    "    for call in response.tool_calls:\n",
    "        tool_name = call['name']  # Use direct access since it should always exist\n",
    "        args = call['args']       # LangChain uses 'args', not 'arguments'\n",
    "        print(\"tool_name: \",tool_name,\"args: \",args)\n",
    "        \n",
    "        # args should already be a dictionary from LangChain\n",
    "        if not isinstance(args, dict):\n",
    "            print(f\"Arguments for {tool_name} are not a dict: {args}\")\n",
    "            continue  # Skip this tool call\n",
    "            \n",
    "        if tool_name in tool_map and args:  # Only proceed if we have valid arguments\n",
    "            try:\n",
    "                # Use .func to call the original function\n",
    "                result = tool_map[tool_name].func(**args)\n",
    "                print(\"result:\",result)\n",
    "                results.append(result)\n",
    "                print(\"results list:\",results)\n",
    "            except Exception as e:\n",
    "                print(f\"Error calling tool {tool_name}: {e}\")\n",
    "                \n",
    "    if results:\n",
    "        prompt = f\"\"\"Based on the tool execution results: {results}, provide a clear final answer.\"\"\"\n",
    "    else:\n",
    "        prompt = \"No tools were executed successfully.\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return {'ans':response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "28d846a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1cff6eb32d0>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(ToolCalling)\n",
    "\n",
    "graph.add_node('tool_or_respond',tool_or_respond)\n",
    "graph.add_node(\"Tool_Call\",Tool_Call)\n",
    "graph.add_node(\"Selfknowledge\",Selfknowledge)\n",
    "\n",
    "graph.add_edge(START,\"tool_or_respond\")\n",
    "graph.add_conditional_edges('tool_or_respond',conditional_node)\n",
    "graph.add_edge(\"Tool_Call\",END)\n",
    "graph.add_edge('Selfknowledge',END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0e357fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "78ad7db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Capital of china',\n",
       " 'ans': AIMessage(content='Beijing', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--cf55c0ad-0a7b-4a20-8299-930f161322e2-0', usage_metadata={'input_tokens': 11, 'output_tokens': 1, 'total_tokens': 34, 'input_token_details': {'cache_read': 0}})}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.invoke({'query':\"Capital of china\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b0af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
